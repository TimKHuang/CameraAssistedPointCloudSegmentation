{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Based Point Cloud Segmentation\n",
    "\n",
    "Kefeng Huang timkhuang@icloud.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import pykitti\n",
    "from kitti_labels import kitti_colors, cityscapes2kitti\n",
    "\n",
    "from predict import predit_on_label\n",
    "from utils import get_poses, get_labels\n",
    "from evaluate import evaluate_sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "This project is using the *Kitti Odometry* dataset for point cloud, images and \n",
    "calibration data and *SemanticKitti* for corresponding labels.\n",
    "\n",
    "* *Kitti Odometry*: http://www.cvlibs.net/datasets/kitti/eval_odometry.php\n",
    "* *SemanticKitti*: http://www.semantic-kitti.org/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "kitti_dataset_path = r'../kitti-dataset'\n",
    "seq = '06'\n",
    "kitti_dataset = pykitti.odometry(kitti_dataset_path, sequence=seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# translate cityscapes label to kitti labels\n",
    "translate = np.vectorize(lambda l: cityscapes2kitti[l])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segmentation based on Image Predicted Labels\n",
    "\n",
    "The first part is directly using the labels predicted with \n",
    "*NVIDIA/Semantic-Segmentation* method using pre-trained *DeepWV3Plus* network\n",
    "model *kitti_best.pth*. \n",
    "\n",
    "This part also tests different number of images to use and evaluates the \n",
    "different using the code adapted from *semanticKitti-api*. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_label_path = f\"../prerun-cam2feature/label/{seq}\"\n",
    "\n",
    "image_label = [\n",
    "    translate(np.load(os.path.join(image_label_path, l)))\n",
    "    for l in sorted(os.listdir(image_label_path))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_index = np.random.randint(len(kitti_dataset))\n",
    "\n",
    "img = kitti_dataset.get_cam2(sample_index)\n",
    "label = image_label[sample_index]\n",
    "colored_pred = np.array([\n",
    "    [kitti_colors[i] for i in row] for row in label\n",
    "])\n",
    "\n",
    "fig, axs = plt.subplots(2)\n",
    "axs[0].imshow(img)\n",
    "axs[1].imshow(colored_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "velo_label_path = f'../kitti-dataset/sequences/{seq}/labels'\n",
    "\n",
    "labels = []\n",
    "for l in sorted(os.listdir(velo_label_path)):\n",
    "    label = np.fromfile(os.path.join(velo_label_path, l), dtype=np.int32)\n",
    "    labels.append(label)\n",
    "\n",
    "print(len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_prev = 3\n",
    "\n",
    "predictions = []\n",
    "\n",
    "for idx, point in enumerate(kitti_dataset.velo):\n",
    "    predictions.append(predit_on_label(\n",
    "        point,\n",
    "        image_label[idx],\n",
    "        kitti_dataset.poses[idx],\n",
    "        get_labels(image_label, max(0, idx - num_prev), idx),\n",
    "        get_poses(kitti_dataset, max(0, idx - num_prev), idx),\n",
    "        kitti_dataset.calib\n",
    "    ))\n",
    "\n",
    "    if idx % 100 == 0:\n",
    "        print(f'{idx} images predictions has completed')\n",
    "\n",
    "mean_ap = evaluate_sequence(predictions, labels)\n",
    "print(f'Mean Average Precision: {mean_ap:2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_prev = 5\n",
    "\n",
    "predictions = []\n",
    "\n",
    "for idx, point in enumerate(kitti_dataset.velo):\n",
    "    predictions.append(predit_on_label(\n",
    "        point,\n",
    "        image_label[idx],\n",
    "        kitti_dataset.poses[idx],\n",
    "        get_labels(image_label, max(0, idx - num_prev), idx),\n",
    "        get_poses(kitti_dataset, max(0, idx - num_prev), idx),\n",
    "        kitti_dataset.calib\n",
    "    ))\n",
    "\n",
    "    if idx % 100 == 0:\n",
    "        print(f'{idx} images predictions has completed')\n",
    "\n",
    "mean_ap = evaluate_sequence(predictions, labels)\n",
    "print(f'Mean Average Precision: {mean_ap:2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_prev = 7\n",
    "\n",
    "predictions = []\n",
    "\n",
    "for idx, point in enumerate(kitti_dataset.velo):\n",
    "    predictions.append(predit_on_label(\n",
    "        point,\n",
    "        image_label[idx],\n",
    "        kitti_dataset.poses[idx],\n",
    "        get_labels(image_label, max(0, idx - num_prev), idx),\n",
    "        get_poses(kitti_dataset, max(0, idx - num_prev), idx),\n",
    "        kitti_dataset.calib\n",
    "    ))\n",
    "\n",
    "    if idx % 100 == 0:\n",
    "        print(f'{idx} images predictions has completed')\n",
    "\n",
    "mean_ap = evaluate_sequence(predictions, labels)\n",
    "print(f'Mean Average Precision: {mean_ap:2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_prev = 9\n",
    "\n",
    "predictions = []\n",
    "\n",
    "for idx, point in enumerate(kitti_dataset.velo):\n",
    "    predictions.append(predit_on_label(\n",
    "        point,\n",
    "        image_label[idx],\n",
    "        kitti_dataset.poses[idx],\n",
    "        get_labels(image_label, max(0, idx - num_prev), idx),\n",
    "        get_poses(kitti_dataset, max(0, idx - num_prev), idx),\n",
    "        kitti_dataset.calib\n",
    "    ))\n",
    "\n",
    "    if idx % 100 == 0:\n",
    "        print(f'{idx} images predictions has completed')\n",
    "\n",
    "mean_ap = evaluate_sequence(predictions, labels)\n",
    "print(f'Mean Average Precision: {mean_ap:2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segmentation based on Image Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c86133f9654398bdd654765ea02a4cf59fafec8d895b16e0614eb51677fdf928"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('lidarseg': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
